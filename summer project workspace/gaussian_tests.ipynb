{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2c60353",
   "metadata": {},
   "source": [
    "# Investigation of Gaussian Convolutions in N dimensional Space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b907f41b",
   "metadata": {},
   "source": [
    "Aims:\n",
    "We propose a solution to the question of replay in the context of catastrophic forgetting. An attempt is made to create a 'net' to capture high-quallity 'reward' input vectors which contribute to learning. These vectors will be used in replay schemes.\n",
    "\n",
    "For useful analysis to be made, there is a need for meaningful variation in input vector space. The current sampling technique uses a gaussian and thus forms an N dimensional sphere which is isotropic. This is not helpful for our analysis of finding high quality points. \n",
    "\n",
    "We attempt to 'mask' the gaussian using convolutions of other probability distributions. \n",
    "\n",
    "Examples include:\n",
    "- Exponential\n",
    "- Tent Function\n",
    "- Uniform Dist (with skew)\n",
    "- Parabolic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6b1598",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23d097ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.special\n",
    "import random\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9843fe",
   "metadata": {},
   "source": [
    "### Test for exponential convolved with gaussian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930ab9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#analytic solution of Ex-Gauss dist:\n",
    "def convolve_exp_norm(alpha, mu, sigma, x):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    alpha = index of exponential\n",
    "    mu = mean of the Gaussian (i.e. the centroid). If none-zero it is an offset\n",
    "    sigma = variance of normal distribution\n",
    "    x = input value\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    co = alpha/2.0 * np.exp( alpha*mu+ alpha*alpha*sigma*sigma/2.0)\n",
    "    x_erf = (mu + alpha*sigma*sigma - x)/(np.sqrt(2.0)*sigma)\n",
    "    y = co * np.exp(-alpha*x) * (1.0 - scipy.special.erf(x_erf))\n",
    "    return y\n",
    "\n",
    "\n",
    "#randomly sample parameters\n",
    "#Debate between using gaussian vs uniform random dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9d9a20",
   "metadata": {},
   "source": [
    "Using a gaussian to randomly sample the parameter values for the convolution will make sure our input distributions are mostly similar and we can highlight the rare events. However, using a uniform dist will allow us to have an unbiased view of which inputs are best..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c080418",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uniform dist\n",
    "alpha = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa15781",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "954a165b5e2e1e721a08ff56dda67b5112531629a0d1c201d72c8216f3e90fc2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
